#version 450

#define NB_HIST 4
#define NB_ORI 8

#define LAMBDA_DESCRIPTOR 3.0f
#define L2_NORM_THRESHOLD 0.2f
#define PI 3.14159265358979323846

struct SIFT_Feat {
  float x;
  float y;
  uint orig_x;
  uint orig_y;
  uint index_scale;
  float sigma;
  float scale_factor;
  float theta;
  float value;
  uint feature_vector[(NB_HIST*NB_HIST*NB_ORI)/4];
};

#define LOCAL_SIZE_X 64
layout(local_size_x = LOCAL_SIZE_X) in;
layout(r32f, binding = 0) uniform image2DArray octave_input;
layout(std430, binding = 1) buffer SIFT_buffer {
    uint nb_elem;
    SIFT_Feat data[];
};

float getImVal(int scale_idx, int x, int y) {
    return imageLoad(octave_input, ivec3(x, y, scale_idx)).r;
}

// Since every thread contribute to the work_feat_vect, we should avoid having each thread
// storing a copy of the 128 float elements in their registers. To avoid that, a single shared
// feature vector is stored in shared memory and threads contribute to it in atomic ops.
// Atomic ops requires some extension to work with floats, here we convert the feature elements to fixed-point
// uint to use them. 
// Range analysis for fixed-point:
//  mag = expf(expf_scale(negative)*(sqr(x)+sqr(y))) * sqrt((gradX*gradX)+(gradY*gradY))
//  mag = expf(negative_value) * sqrt(([-1;1]*[-1;1])+([-1;1]*[-1;1]))
//  mag = expf(negative_value) * sqrt([0;1]+([0;1]) = expf(negative_value) * sqrt([0;2])
//
//  Here the mag value depends on the gradientXY norm with a max value of sqrt(2) and depends
//  on the result of the exponential function that gives less importance [0,1] to pixels
//  far from the box center.
//  Contribution factor multiplied to mag before adding to val_to_add is in [0;1]
//  
//  Multiple pixels in the pixel box can contribute to the same element in the feature vector. To do so
//  they must correspond to the same orientation bin and to the same patch inside the box.
//  Given the box radius, the max number of pixel for the single element should be
//  (box_radius/(NB_HIST/2))^2 = max number of pixel in a patch
//  Since the exponential function gives less importance to pixels far from the box center, the 4 patch
//  around the center can have the maximum value, so the max value possible in a single feature elem can only be 
//  reached in one of these patch.
//  With this result, the maximum value stored (float) should be sum_4_every_pix_in_patch_near_center( expf(x,y) * sqrt(2) )
//  When the feature vector is filled, to compute the feature vector norm without using double precision,
//  we need to make sure that feat_vec_elem^2 do not overflow.
//  Therefore, the upper bound for every feature vector element (in FP) will be in below 2^16 since 2^16 * 2^16 = 2^32
//  
//  We know that the FP element should be below 2^16 and that the maximum value possible to any element is
//  max_val = sum_4_every_pix_in_patch_near_center( expf(x,y) * sqrt(2) )
//  max_val requires ceil(log2(max_val)) bits to be represented (as an uint) so we can convert from float to uint
//  by multiplying the float by 2^(16-ceil(log2(max_val))). This way we use the max number of bits possible
//  so the best precision and still ensure no overflow during the norm computation.
//
//  There's a few drawbacks here:
//      - As the box size (or proportionally the keypoint sigma) increases, the precision of the computation will
//        decrease. With the standard SIFT parameters (sigma 1.6 and 3 scale per octave), float values were multiplied by 2^12,
//        providing precision near results with float computations. Matching performances after this change were not affected by these change. 
//      - We must compute the fixed point conversion online... we lose a bit of time here but not much

shared uint work_feat_vect[NB_HIST*NB_HIST*NB_ORI];
shared SIFT_Feat kp;
shared uint euclidean_norm_acc;
shared float euclidean_norm;

void main() {
    int local_id = int(gl_LocalInvocationID.x);
    if(local_id==0) {
        // Get keypoint for which descriptor will be computed
        kp = data[gl_WorkGroupID.x];

        // Zeroing descriptor memspace and shared feature vector
        for(int i=0; i<NB_HIST*NB_HIST*NB_ORI;i++) {
            work_feat_vect[i] = 0;
        }
        for (int i = 0; i < (NB_HIST*NB_HIST*NB_ORI)/4; i++)
        {
            kp.feature_vector[i] = 0;
        }
    }
    barrier();
    memoryBarrierShared();


    int image_width = imageSize(octave_input).x;
    int image_height = imageSize(octave_input).y;

    float scaled_lambda_desc = LAMBDA_DESCRIPTOR * (kp.sigma / kp.scale_factor);
    float radius = sqrt(2.f) * scaled_lambda_desc *(NB_HIST+1) * 0.5;
    int int_radius = int(floor(radius+0.5f));

    float keypoint_cos = cos(kp.theta)/scaled_lambda_desc;
    float keypoint_sin = sin(kp.theta)/scaled_lambda_desc;

    float expf_scale = -1.f / (2.f * (NB_HIST/2) * (NB_HIST/2));

    // Compute conversion to fixed point (see explanation above)
    float max_elem_val = 0.f;
    for(int i=0; i<int_radius/2;i++) {
        max_elem_val += exp(expf_scale * ((i * i) + (i * i)))*sqrt(2);
        for(int j=i+1; j<int_radius/2;j++) {
            max_elem_val += exp(expf_scale * ((i * i) + (j * j)))*sqrt(2)*2;
        }
    }
    float fp_convertor = float(1<<uint(16 - ceil(log2(max_elem_val))));

    int box_size = (int_radius*2)+1;
    for(int pix_idx=local_id; pix_idx<(box_size*box_size); pix_idx+=LOCAL_SIZE_X) {
        int delta_y = (pix_idx/box_size)-int_radius;
        int delta_x = (pix_idx%box_size)-int_radius;
        int idx_x = int(kp.x) + delta_x;
        int idx_y = int(kp.y) + delta_y;

        if(idx_x<1 || idx_x>=(image_width-1) || idx_y<1 || idx_y>=(image_height-1)) {
            continue;
        }

        // Rotate indexes by keypoint orientation
        float oriented_x = keypoint_cos * float(delta_x) + keypoint_sin * float(delta_y);
        float oriented_y = keypoint_cos * float(delta_y) - keypoint_sin * float(delta_x);

        float gradX = 0.5f * (getImVal(int(kp.index_scale), idx_x+1, idx_y) - getImVal(int(kp.index_scale), idx_x-1, idx_y));
        float gradY = 0.5f * (getImVal(int(kp.index_scale), idx_x, idx_y+1) - getImVal(int(kp.index_scale), idx_x, idx_y-1));
        float orientation = atan(gradY,gradX)-kp.theta;
        // Cap orientation in [0, 2xPI]
        if(orientation<0) {
            orientation += 2.f*PI;
        }
        else if(orientation > (2.f*PI)) {
            orientation -= 2.f*PI;
        }
        float mag = exp(expf_scale * ((oriented_x * oriented_x) + (oriented_y * oriented_y)))*sqrt((gradX*gradX)+(gradY*gradY));

        // Compute histogram indexes
        float fhist_x_idx = oriented_x + (NB_HIST/2);
        float fhist_y_idx = oriented_y + (NB_HIST/2);
        float fbin_idx = orientation * float(NB_ORI) / (2.f * PI);

        int hist_x_idx = int(floor(fhist_x_idx -0.5));
        int hist_y_idx = int(floor(fhist_y_idx -0.5));
        int bin_idx = int(floor(fbin_idx));
        if (hist_x_idx < 0 || hist_x_idx>=NB_HIST || hist_y_idx < 0 || hist_y_idx>=NB_HIST)
        {
            continue;
        }
        float rhist_x_idx = fhist_x_idx - (float(hist_x_idx)+0.5);
        float rhist_y_idx = fhist_y_idx - (float(hist_y_idx)+0.5);
        float rbin_idx = fbin_idx-float(bin_idx);

        // Disperse contribution into the two nearest histograms and bins
        for (int i = 0; i < 2; i++)
        {
            for (int j = 0; j < 2; j++)
            {
                for (int k = 0; k < 2; k++)
                {
                    if((i+hist_x_idx)>= 0 && (i+hist_x_idx)<NB_HIST && (j+hist_y_idx)>=0 && (j+hist_y_idx)<NB_HIST) {
                        int feat_vec_idx = (j+hist_y_idx) * NB_HIST * NB_ORI + (i+hist_x_idx) * NB_ORI + ((k+bin_idx)%NB_ORI);
                        float val_to_add = abs(1.f - i - rhist_x_idx) * abs(1.f - j - rhist_y_idx) * abs(1.f - k - rbin_idx) * mag;
                        // Convert float to fixed point representation
                        atomicAdd(work_feat_vect[feat_vec_idx], uint(val_to_add*fp_convertor));
                    }
                }
            }
        }
    }


    if(local_id==0) {
        euclidean_norm_acc = 0;
    }
    barrier();
    memoryBarrierShared();

    // Post processing step on feature vector
    // Compute Euclidean norm
    for (int i = local_id; i < NB_HIST * NB_HIST * NB_ORI; i+=LOCAL_SIZE_X)
    {
        atomicAdd(euclidean_norm_acc,work_feat_vect[i] * work_feat_vect[i]);
    }
    barrier();
    memoryBarrierShared();
    if(local_id==0) {
        euclidean_norm = sqrt(float(euclidean_norm_acc));
    }
    barrier();
    memoryBarrierShared();
    // Saturate features to a threshold of the feature vector L2 norm
    for (int i = local_id; i < NB_HIST * NB_HIST * NB_ORI; i+=LOCAL_SIZE_X)
    {
        work_feat_vect[i] = min(work_feat_vect[i], uint(euclidean_norm * L2_NORM_THRESHOLD));
    }
    barrier();
    memoryBarrierShared();
    if(local_id==0) {
        euclidean_norm_acc = 0;
    }
    barrier();
    memoryBarrierShared();
    // Recompute Euclidean norm
    for (int i = local_id; i < NB_HIST * NB_HIST * NB_ORI; i+=LOCAL_SIZE_X)
    {
        atomicAdd(euclidean_norm_acc,work_feat_vect[i] * work_feat_vect[i]);
    }
    barrier();
    memoryBarrierShared();
    if(local_id==0) {
        euclidean_norm = sqrt(float(euclidean_norm_acc));
    }
    barrier();
    memoryBarrierShared();

    // Convert feature vector element to uint8 and write values to descriptor
    for (uint i = local_id; i < NB_HIST*NB_HIST*NB_ORI; i+=LOCAL_SIZE_X)
    {
        uint u32_idx = i>>2;
        uint u8_idx = i&(3u);

        float work_feat_val = float(work_feat_vect[u32_idx*4 + u8_idx]) * (512.f / euclidean_norm);
        if (work_feat_val < 0.f)
        {
            // Do nothing since it's already 0, this case should be impossible anyway
            //feat_val |= 0u;
        }
        else if (work_feat_val > 255.f)
        {
            atomicOr(kp.feature_vector[u32_idx], 255<<(8*u8_idx));
        }
        else
        {
            atomicOr(kp.feature_vector[u32_idx], uint(work_feat_val)<<(8*u8_idx));
        }
    }
    
    barrier();
    memoryBarrierShared();

    if(local_id==0) {
        data[gl_WorkGroupID.x] = kp;
    }

}